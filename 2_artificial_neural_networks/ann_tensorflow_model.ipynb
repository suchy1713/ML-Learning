{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann_tensorflow_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMAUUTULlxWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def init_weights(M1, M2):\n",
        "    return np.random.randn(M1, M2)/np.sqrt(M1), np.zeros(M2)\n",
        "\n",
        "class HiddenLayer(object):\n",
        "    def __init__(self, M1, M2, f):\n",
        "        self.M1 = M1\n",
        "        self.M2 = M2\n",
        "        self.f = f\n",
        "        W, b = init_weights(M1, M2)\n",
        "        self.W = tf.Variable(W.astype(np.float32))\n",
        "        self.b = tf.Variable(b.astype(np.float32))\n",
        "        self.params = [self.W, self.b]\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.f(tf.matmul(X, self.W) + self.b)\n",
        "\n",
        "class ANN(object):\n",
        "    def __init__(self, hidden_layer_sizes):\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "\n",
        "    def fit(self, X, Y, activation=tf.nn.relu, learning_rate=1e-3, mu=0.99, reg=0, epochs=100, batch_size=None, print_period=10, show_fig=True):\n",
        "        X = X.astype(np.float32)\n",
        "        Y = Y.astype(np.int32)\n",
        "        N, D = X.shape\n",
        "        self.layers = []\n",
        "\n",
        "        #add hidden layers\n",
        "        M1 = D\n",
        "        for M2 in self.hidden_layer_sizes:\n",
        "            h = HiddenLayer(M1, M2, activation)\n",
        "            self.layers.append(h)\n",
        "            M1 = M2\n",
        "\n",
        "        #and output layer\n",
        "        K = Y.shape[1]\n",
        "        h = HiddenLayer(M1, K, tf.identity)\n",
        "        self.layers.append(h)\n",
        "\n",
        "        if batch_size == None:\n",
        "            batch_size = N\n",
        "\n",
        "        self.weights = []\n",
        "        for h in self.layers:\n",
        "            self.weights += h.params\n",
        "\n",
        "        #data as tf variables\n",
        "        tfX = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
        "        tfY = tf.placeholder(tf.float32, shape=(None, K), name='Y')\n",
        "        Yish = self.forward(tfX)\n",
        "\n",
        "        reg_pen = reg*sum([tf.nn.l2_loss(w) for w in self.weights])\n",
        "        cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Yish, labels=tfY)) + reg_pen\n",
        "        train_op = tf.train.RMSPropOptimizer(learning_rate, decay=0.99, momentum=mu).minimize(cost)\n",
        "        predict_op = tf.argmax(Yish, 1)\n",
        "\n",
        "        #main training loop\n",
        "        costs = []\n",
        "        init = tf.global_variables_initializer()\n",
        "        n_batches = N//batch_size\n",
        "        with tf.Session() as session:\n",
        "            session.run(init) \n",
        "            for i in range(epochs+1):\n",
        "                for j in range(n_batches):\n",
        "                    X_batch = X[j*batch_size:(j*batch_size + batch_size),]\n",
        "                    Y_batch = Y[j*batch_size:(j*batch_size + batch_size),]\n",
        "\n",
        "                    session.run(train_op, feed_dict={tfX: X_batch, tfY: Y_batch})\n",
        "                c = session.run(cost, feed_dict={tfX: X_batch, tfY: Y_batch})\n",
        "                costs.append(c)\n",
        "                if i%print_period == 0:\n",
        "                    print('Epoch ', i ,'/', epochs, ': Cost: ', c)\n",
        "\n",
        "            if show_fig:\n",
        "                plt.plot(costs)\n",
        "                plt.show()\n",
        "\n",
        "    def forward(self, X):\n",
        "        p = X\n",
        "        for h in self.layers:\n",
        "            p = h.forward(p)\n",
        "\n",
        "        return p\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.forward(X.astype(np.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}