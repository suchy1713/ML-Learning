{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann_theano_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc7ci7LXTtw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"ann_theano_model.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1xwn7DYqyEDKrdQ9atMc6LRIAOWGyLKMV\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def init_weights(M1, M2):\n",
        "    return np.random.randn(M1, M2)/np.sqrt(M1), np.zeros(M2)\n",
        "\n",
        "class HiddenLayer(object):\n",
        "    def __init__(self, M1, M2, f):\n",
        "        self.M1 = M1\n",
        "        self.M2 = M2\n",
        "        self.f = f\n",
        "        W, b = init_weights(M1, M2)\n",
        "        self.W = theano.shared(W)\n",
        "        self.b = theano.shared(b)\n",
        "        self.params = [self.W, self.b]\n",
        "\n",
        "    def forward(self, X):\n",
        "        if self.f == T.nnet.relu:\n",
        "            return self.f(X.dot(self.W) + self.b, alpha= 0.1)\n",
        "        return self.f(X.dot(self.W) + self.b)\n",
        "\n",
        "class ANN(object):\n",
        "    def __init__(self, hidden_layer_sizes):\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "\n",
        "    def fit(self, X, Y, X_test, Y_test, activation=T.nnet.relu, learning_rate=1e-3, mu=0.99, reg=0, epochs=100, batch_size=None, print_period=10, show_fig=True, decay=0.999, eps=10e-10):\n",
        "        X = X.astype(np.float32)\n",
        "        Y = Y.astype(np.int32)\n",
        "        N, D = X.shape\n",
        "        self.layers = []\n",
        "\n",
        "        #add hidden layers\n",
        "        M1 = D\n",
        "        for M2 in self.hidden_layer_sizes:\n",
        "            h = HiddenLayer(M1, M2, activation)\n",
        "            self.layers.append(h)\n",
        "            M1 = M2\n",
        "\n",
        "        #and output layer\n",
        "        K = Y.shape[1]\n",
        "        h = HiddenLayer(M1, K, T.nnet.softmax)\n",
        "        self.layers.append(h)\n",
        "\n",
        "        if batch_size == None:\n",
        "            batch_size = N\n",
        "\n",
        "        self.weights = []\n",
        "        for h in self.layers:\n",
        "            self.weights += h.params\n",
        "\n",
        "        #data as theano variables\n",
        "        thX = T.matrix('X')\n",
        "        thY = T.matrix('Y')\n",
        "        p_y_given_x = self.forward(thX)\n",
        "\n",
        "        velocities = [theano.shared(np.zeros_like(w.get_value())) for w in self.weights]\n",
        "        caches = [theano.shared(np.ones_like(w.get_value())) for w in self.weights]\n",
        "\n",
        "        reg_pen = reg*T.mean([(w*w).sum() for w in self.weights])\n",
        "        cost = -((thY*T.log(p_y_given_x)).sum() + reg_pen)\n",
        "        predictions = T.argmax(p_y_given_x, axis=1)\n",
        "        grads = T.grad(cost, self.weights)\n",
        "\n",
        "        updates =  [(c, decay*c + (1-decay)*(g*g)) for c, g in zip(caches, grads)] + [(v, mu*v.get_value() - learning_rate * g/(T.sqrt(decay*c + (1-decay)*(g*g)) + eps)) for v, g, c in zip(velocities, grads, caches)] + [(w, w + mu*v.get_value() - learning_rate*g/(T.sqrt(decay*c + (1-decay)*(g*g)) + eps)) for w, v, g, c in zip(self.weights, velocities, grads, caches)]\n",
        "\n",
        "        #functions\n",
        "        train = theano.function(\n",
        "            inputs=[thX, thY],\n",
        "            updates=updates,\n",
        "            outputs=[cost, predictions]\n",
        "        )\n",
        "\n",
        "        self.get_prediction = theano.function(\n",
        "            inputs=[thX],\n",
        "            outputs=predictions\n",
        "        )\n",
        "\n",
        "        #main training loop\n",
        "        costs = []\n",
        "        c_rates = []\n",
        "        n_batches = N//batch_size\n",
        "        for i in range(epochs+1):\n",
        "            for j in range(n_batches):\n",
        "                X_batch = X[j*batch_size:(j*batch_size + batch_size),]\n",
        "                Y_batch = Y[j*batch_size:(j*batch_size + batch_size),]\n",
        "\n",
        "                c, _ = train(X_batch, Y_batch)\n",
        "\n",
        "            costs.append(c)\n",
        "            c_r = self.score(X_test, Y_test)\n",
        "            c_rates.append(c_r)\n",
        "            if i%print_period == 0:\n",
        "                print('Epoch ', i ,'/', epochs, ': Cost: ', c, ' Classification rate: ', c_r)\n",
        "\n",
        "        if show_fig:\n",
        "            plt.plot(costs)\n",
        "            plt.show()\n",
        "            plt.plot(c_rates)\n",
        "            plt.show()\n",
        "\n",
        "    def forward(self, X):\n",
        "        p = X\n",
        "        for h in self.layers:\n",
        "            p = h.forward(p)\n",
        "\n",
        "        return p\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.get_prediction(X)\n",
        "\n",
        "    def score(self, X, Y):\n",
        "        P = self.get_prediction(X)\n",
        "        T = Y.argmax(axis=1)\n",
        "        return np.mean(P == T)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}