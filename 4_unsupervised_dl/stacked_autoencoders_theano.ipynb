{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stacked_autoencoders_theano.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkhB8URqPGKqnvTQdd1LCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suchy1713/ML-Learning/blob/master/4_unsupervised_dl/stacked_autoencoders_theano.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mllBiArrRcwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"ann_theano_model.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1xwn7DYqyEDKrdQ9atMc6LRIAOWGyLKMV\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def init_weights(M1, M2):\n",
        "    return np.random.randn(M1, M2)/np.sqrt(M1)\n",
        "\n",
        "def error_rate(p, t):\n",
        "    return np.mean(p != t)\n",
        "\n",
        "class Autoencoder(object):\n",
        "    def __init__(self, M, an_id):\n",
        "        self.M = M\n",
        "        self.id = an_id\n",
        "\n",
        "    def fit(self, X, learning_rate=0.5, mu=0.99, epochs=1, batch_sz=100, show_fig=True):\n",
        "        N, D = X.shape\n",
        "        n_batches = N//batch_sz\n",
        "\n",
        "        W0 = init_weights(D, self.M)\n",
        "        self.W = theano.shared(W0, 'W_'+str(self.id))\n",
        "        self.bh = theano.shared(np.zeros(self.M), 'bh_'+str(self.id))\n",
        "        self.bo = theano.shared(np.zeros(D), 'bo_'+str(self.id))\n",
        "        self.params = [self.W, self.bh, self.bo]\n",
        "        self.forward_params = [self.W,  self.bh]\n",
        "\n",
        "        self.dW = theano.shared(np.zeros((D, self.M)), 'dW_'+str(self.id))\n",
        "        self.dbh = theano.shared(np.zeros(self.M), 'dbh_'+str(self.id))\n",
        "        self.dbo = theano.shared(np.zeros(D), 'dbo_'+str(self.id))\n",
        "        self.dparams = [self.dW, self.dbh, self.dbo]\n",
        "        self.dforward_params = [self.dW,  self.dbh]\n",
        "\n",
        "        X_in = T.matrix('X'+str(self.id))\n",
        "        X_hat = self.forward_output(X_in)\n",
        "\n",
        "        H = T.nnet.sigmoid(X_in.dot(self.W) + self.bh)\n",
        "        self.hidden_op = theano.function(\n",
        "            inputs=[X_in],\n",
        "            outputs=H\n",
        "        )\n",
        "\n",
        "        cost = -(X_in*T.log(X_hat) + (1-X_in)*T.log(1-X_hat)).flatten().mean()\n",
        "        cost_op = theano.function(\n",
        "            inputs=[X_in],\n",
        "            outputs=cost\n",
        "        )\n",
        "\n",
        "        updates = [\n",
        "                   (dp, mu*dp - learning_rate*T.grad(cost, p)) for p, dp in zip(self.params, self.dparams)\n",
        "        ] + [\n",
        "             (p, p + mu*dp - learning_rate*T.grad(cost, p)) for p, dp in zip(self.params, self.dparams)\n",
        "        ]\n",
        "\n",
        "        train_op = theano.function(\n",
        "            inputs=[X_in],\n",
        "            updates=updates\n",
        "        )\n",
        "\n",
        "        self.predict = theano.function(\n",
        "                    inputs=[X_in],\n",
        "                    outputs=X_hat,\n",
        "                )\n",
        "\n",
        "        costs = []\n",
        "        print('Training autoencoder ' + str(self.id+1))\n",
        "        for i in range(epochs):\n",
        "            print('Epoch ', i+1, end=' ')\n",
        "            X = shuffle(X)\n",
        "            for j in range(n_batches):\n",
        "                batch = X[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "                train_op(batch)\n",
        "                cost = cost_op(batch)\n",
        "                costs.append(cost)\n",
        "            print('Cost: ', cost)\n",
        "\n",
        "        if show_fig:\n",
        "            plt.plot(costs)\n",
        "            plt.show()\n",
        "\n",
        "    def forward_hidden(self, X):\n",
        "        Z = T.nnet.sigmoid(X.dot(self.W) + self.bh)\n",
        "        return Z\n",
        "\n",
        "    def forward_output(self, X):\n",
        "        Z = self.forward_hidden(X)\n",
        "        Y = T.nnet.sigmoid(Z.dot(self.W.T) + self.bo)\n",
        "        return Y \n",
        "\n",
        "\n",
        "class StackedAE(object):\n",
        "    def __init__(self, hidden_layer_sizes):\n",
        "        self.hidden_layers = []\n",
        "        count = 0\n",
        "        for M in hidden_layer_sizes:\n",
        "            ae = Autoencoder(M, count)\n",
        "            self.hidden_layers.append(ae)\n",
        "            count += 1\n",
        "\n",
        "    def fit(self, X, Y, Xtest, Ytest, pretrain=True, learning_rate=0.1, mu=0.99, reg=0, epochs=1, batch_sz=100):\n",
        "        pretrain_epochs = int(pretrain)\n",
        "\n",
        "        current_input = X\n",
        "        for ae in self.hidden_layers:\n",
        "            ae.fit(current_input, epochs=2, show_fig=False)\n",
        "            current_input = ae.hidden_op(current_input)\n",
        "\n",
        "        N = len(Y)\n",
        "        K = len(set(Y))\n",
        "        W0 = init_weights(self.hidden_layers[-1].M, K)\n",
        "        self.W = theano.shared(W0, 'W_lr')\n",
        "        self.b = theano.shared(np.zeros(K), 'b_lr')\n",
        "\n",
        "        self.params = [self.W, self.b]\n",
        "        for ae in self.hidden_layers:\n",
        "            self.params += ae.forward_params\n",
        "\n",
        "        self.dW = theano.shared(np.zeros((self.hidden_layers[-1].M, K)), 'dW_lr')\n",
        "        self.db = theano.shared(np.zeros(K), 'db_lr')\n",
        "\n",
        "        self.dparams = [self.dW, self.db]\n",
        "        for ae in self.hidden_layers:\n",
        "            self.dparams += ae.dforward_params\n",
        "\n",
        "        X_in = T.matrix('X_in')\n",
        "        targets = T.ivector('targets')\n",
        "        pY = self.forward(X_in)\n",
        "\n",
        "        reg_cost = T.sum([(p*p).sum() for p in self.params])\n",
        "        cost = -T.mean(T.log(pY[T.arange(pY.shape[0]), targets])) + reg*reg_cost\n",
        "        prediction = self.predict(X_in)\n",
        "        cost_predict_op = theano.function(\n",
        "            inputs = [X_in, targets],\n",
        "            outputs = [cost, prediction]\n",
        "        )\n",
        "\n",
        "        updates = [\n",
        "                   (dp, mu*dp - learning_rate*T.grad(cost, p)) for p, dp in zip(self.params, self.dparams)\n",
        "        ] + [\n",
        "             (p, p + mu*dp - learning_rate*T.grad(cost, p)) for p, dp in zip(self.params, self.dparams)\n",
        "        ]\n",
        "\n",
        "        train_op = theano.function(\n",
        "            inputs = [X_in, targets],\n",
        "            updates = updates\n",
        "        )\n",
        "\n",
        "        n_batches = N // batch_sz\n",
        "        costs = []\n",
        "\n",
        "        print('Supervised learning:')\n",
        "        for i in range(epochs):\n",
        "            print('epoch ', i+1, end=' ')\n",
        "            X, Y = shuffle(X, Y) \n",
        "\n",
        "            for j in range(n_batches):\n",
        "                X_batch = X[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "                Y_batch = Y[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "\n",
        "                train_op(X_batch, Y_batch)\n",
        "                cost, prediction = cost_predict_op(Xtest, Ytest)\n",
        "                error = error_rate(prediction, Ytest)\n",
        "                costs.append(cost)\n",
        "            print('Cost: ', cost, ' Error: ', error)\n",
        "        plt.plot(costs)\n",
        "        plt.show()\n",
        "\n",
        "    def predict(self, X):\n",
        "        return T.argmax(self.forward(X), axis=1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        current_input = X\n",
        "        for ae in self.hidden_layers:\n",
        "            Z = ae.forward_hidden(current_input)\n",
        "            current_input = Z\n",
        "\n",
        "        Y = T.nnet.softmax(T.dot(current_input, self.W) + self.b)\n",
        "        return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc1EMPofX12W",
        "colab_type": "code",
        "outputId": "f3289e25-d882-4a14-df5e-620513461712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train = shuffle(x_train, y_train)\n",
        "x_test, y_test = shuffle(x_test, y_test)\n",
        "x_train, x_test, y_train, y_test = x_train[:1000, :], x_test[:1000, :], y_train[:1000], y_test[:1000]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "y_train, y_test = y_train.astype(np.int32), y_test.astype(np.int32)\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "dnn = StackedAE([1000, 750, 500])\n",
        "dnn.fit(x_train, y_train, x_test, y_test, epochs=100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training autoencoder 1\n",
            "Epoch  1 Cost:  0.2641845614538393\n",
            "Epoch  2 Cost:  0.28083726863194985\n",
            "Training autoencoder 2\n",
            "Epoch  1 Cost:  0.6658532758905681\n",
            "Epoch  2 Cost:  0.6757685063919143\n",
            "Training autoencoder 3\n",
            "Epoch  1 Cost:  0.5801523888288164\n",
            "Epoch  2 Cost:  0.5707128352280502\n",
            "Supervised learning:\n",
            "epoch  1 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  rval = inputs[0].__getitem__(inputs[1:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cost:  2.308396424194697  Error:  0.881\n",
            "epoch  2 Cost:  2.2221439792396533  Error:  0.869\n",
            "epoch  3 Cost:  2.073727821504011  Error:  0.767\n",
            "epoch  4 Cost:  2.09064506886743  Error:  0.791\n",
            "epoch  5 Cost:  2.023426159533727  Error:  0.721\n",
            "epoch  6 Cost:  2.012176804931931  Error:  0.76\n",
            "epoch  7 Cost:  1.9623978225465553  Error:  0.708\n",
            "epoch  8 Cost:  1.9256583958237339  Error:  0.72\n",
            "epoch  9 Cost:  1.8805838497270981  Error:  0.673\n",
            "epoch  10 Cost:  1.8643852454164855  Error:  0.695\n",
            "epoch  11 Cost:  1.762463247487934  Error:  0.648\n",
            "epoch  12 Cost:  1.6721282661448484  Error:  0.644\n",
            "epoch  13 Cost:  1.6415360383673656  Error:  0.653\n",
            "epoch  14 Cost:  1.712439446603363  Error:  0.661\n",
            "epoch  15 Cost:  1.5980878599222554  Error:  0.634\n",
            "epoch  16 Cost:  1.5676849042054315  Error:  0.61\n",
            "epoch  17 Cost:  1.5158012377592127  Error:  0.61\n",
            "epoch  18 Cost:  1.4951693216666115  Error:  0.619\n",
            "epoch  19 Cost:  1.4847492570001466  Error:  0.603\n",
            "epoch  20 Cost:  1.443225413710164  Error:  0.57\n",
            "epoch  21 Cost:  1.4058433149062375  Error:  0.538\n",
            "epoch  22 Cost:  1.3709227966357131  Error:  0.549\n",
            "epoch  23 Cost:  1.303724340930809  Error:  0.518\n",
            "epoch  24 Cost:  1.2503154887874934  Error:  0.485\n",
            "epoch  25 Cost:  1.204009969108046  Error:  0.468\n",
            "epoch  26 Cost:  1.177098521930854  Error:  0.453\n",
            "epoch  27 Cost:  1.0900826253542255  Error:  0.39\n",
            "epoch  28 Cost:  1.0074572515439568  Error:  0.372\n",
            "epoch  29 Cost:  0.9976690512095103  Error:  0.352\n",
            "epoch  30 Cost:  0.971771264993371  Error:  0.338\n",
            "epoch  31 Cost:  0.9395552881890548  Error:  0.316\n",
            "epoch  32 Cost:  0.923857538688607  Error:  0.291\n",
            "epoch  33 Cost:  0.871293496995373  Error:  0.277\n",
            "epoch  34 Cost:  0.8487319688733226  Error:  0.27\n",
            "epoch  35 Cost:  0.8609130111278301  Error:  0.241\n",
            "epoch  36 Cost:  0.8378209895507154  Error:  0.245\n",
            "epoch  37 Cost:  0.8858187462408453  Error:  0.241\n",
            "epoch  38 Cost:  0.9104812259962525  Error:  0.223\n",
            "epoch  39 Cost:  0.8559383964838595  Error:  0.212\n",
            "epoch  40 Cost:  0.9555548013793742  Error:  0.216\n",
            "epoch  41 Cost:  0.8871500118326839  Error:  0.215\n",
            "epoch  42 Cost:  0.8182742135940934  Error:  0.185\n",
            "epoch  43 Cost:  0.8346447347048052  Error:  0.192\n",
            "epoch  44 Cost:  0.7661555041234934  Error:  0.164\n",
            "epoch  45 Cost:  0.8357125405167233  Error:  0.171\n",
            "epoch  46 Cost:  0.7823091377320459  Error:  0.153\n",
            "epoch  47 Cost:  0.8338362687459209  Error:  0.152\n",
            "epoch  48 Cost:  0.8457519758017008  Error:  0.156\n",
            "epoch  49 Cost:  0.8312806591222145  Error:  0.147\n",
            "epoch  50 Cost:  0.8110028814083595  Error:  0.157\n",
            "epoch  51 Cost:  0.8057408483058379  Error:  0.148\n",
            "epoch  52 Cost:  0.8994534537531108  Error:  0.146\n",
            "epoch  53 Cost:  0.9689747541208269  Error:  0.153\n",
            "epoch  54 Cost:  1.0177023312255804  Error:  0.143\n",
            "epoch  55 Cost:  0.9124843196720497  Error:  0.144\n",
            "epoch  56 Cost:  0.8610150657878515  Error:  0.144\n",
            "epoch  57 Cost:  0.9108545668622599  Error:  0.141\n",
            "epoch  58 Cost:  0.9745148489538662  Error:  0.145\n",
            "epoch  59 Cost:  1.0326324039770092  Error:  0.146\n",
            "epoch  60 Cost:  0.9910850841865968  Error:  0.149\n",
            "epoch  61 Cost:  1.0255944088155164  Error:  0.154\n",
            "epoch  62 Cost:  1.0183958119422696  Error:  0.15\n",
            "epoch  63 Cost:  1.0144182466173393  Error:  0.14\n",
            "epoch  64 Cost:  1.028732460712653  Error:  0.136\n",
            "epoch  65 Cost:  1.0187309629825847  Error:  0.13\n",
            "epoch  66 Cost:  1.0267126281141057  Error:  0.132\n",
            "epoch  67 Cost:  1.0361000964766545  Error:  0.127\n",
            "epoch  68 Cost:  1.0408312911550897  Error:  0.135\n",
            "epoch  69 Cost:  1.0312007295013925  Error:  0.129\n",
            "epoch  70 Cost:  1.032357227573379  Error:  0.127\n",
            "epoch  71 Cost:  1.0497752812212275  Error:  0.129\n",
            "epoch  72 Cost:  1.0691303869062556  Error:  0.132\n",
            "epoch  73 Cost:  1.08888012200084  Error:  0.138\n",
            "epoch  74 Cost:  1.1056192469947608  Error:  0.139\n",
            "epoch  75 Cost:  1.1192176666027727  Error:  0.143\n",
            "epoch  76 Cost:  1.1276507178110908  Error:  0.141\n",
            "epoch  77 Cost:  1.1313505435535345  Error:  0.143\n",
            "epoch  78 Cost:  1.1303155489373806  Error:  0.145\n",
            "epoch  79 Cost:  1.1279490149725548  Error:  0.144\n",
            "epoch  80 Cost:  1.1249257575885638  Error:  0.141\n",
            "epoch  81 Cost:  1.122149595314112  Error:  0.14\n",
            "epoch  82 Cost:  1.1198191317417767  Error:  0.141\n",
            "epoch  83 Cost:  1.1183485197836125  Error:  0.138\n",
            "epoch  84 Cost:  1.1183219726442089  Error:  0.135\n",
            "epoch  85 Cost:  1.1191637640529608  Error:  0.134\n",
            "epoch  86 Cost:  1.1206991033180924  Error:  0.133\n",
            "epoch  87 Cost:  1.122859260735135  Error:  0.132\n",
            "epoch  88 Cost:  1.1256835633415572  Error:  0.136\n",
            "epoch  89 Cost:  1.128658950435795  Error:  0.135\n",
            "epoch  90 Cost:  1.132100660531495  Error:  0.137\n",
            "epoch  91 Cost:  1.1357254891365207  Error:  0.136\n",
            "epoch  92 Cost:  1.1394308099162092  Error:  0.137\n",
            "epoch  93 Cost:  1.1431643425337048  Error:  0.138\n",
            "epoch  94 Cost:  1.1467475676829721  Error:  0.138\n",
            "epoch  95 Cost:  1.1501896999712062  Error:  0.137\n",
            "epoch  96 Cost:  1.1533324893946195  Error:  0.137\n",
            "epoch  97 Cost:  1.156144257766208  Error:  0.137\n",
            "epoch  98 Cost:  1.1587812993937705  Error:  0.14\n",
            "epoch  99 Cost:  1.1610948965190409  Error:  0.14\n",
            "epoch  100 Cost:  1.1630567345108471  Error:  0.139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}