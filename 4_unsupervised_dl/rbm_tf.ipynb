{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rbm_tf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPN9EttvuZ6sOMQY87gklGk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1LXCi8XoU-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def error_rate(y, p):\n",
        "    return np.mean(y != p)\n",
        "\n",
        "class RBM(object):\n",
        "    def __init__(self, D, M, id):\n",
        "        self.id = id\n",
        "        self.D = D\n",
        "        self.build(D, M)\n",
        "\n",
        "    def set_session(self, session):\n",
        "        self.session = session\n",
        "\n",
        "    def build(self, D, M):\n",
        "        self.W = tf.Variable(tf.random_normal(shape=(D, M)))\n",
        "        self.c = tf.Variable(np.zeros(M).astype(np.float32))\n",
        "        self.b = tf.Variable(np.zeros(D).astype(np.float32))\n",
        "\n",
        "        self.X_in = tf.placeholder(tf.float32, shape=(None,D))\n",
        "\n",
        "        self.p_h_given_v = tf.nn.sigmoid(tf.matmul(self.X_in, self.W) + self.c)\n",
        "        r = tf.random_uniform(shape=tf.shape(self.p_h_given_v))\n",
        "        H = tf.cast(r < self.p_h_given_v, tf.float32)\n",
        "\n",
        "        p_v_given_h = tf.nn.sigmoid(tf.matmul(H, tf.transpose(self.W)) + self.b)\n",
        "        r = tf.random_uniform(shape=tf.shape(p_v_given_h))\n",
        "        X_sample = tf.cast(r < p_v_given_h, tf.float32)\n",
        "\n",
        "        objective = tf.reduce_mean(self.free_energy(self.X_in)) - tf.reduce_mean(self.free_energy(X_sample))\n",
        "        self.train_op = tf.train.AdamOptimizer(1e-2).minimize(objective)\n",
        "\n",
        "        logits = self.forward_logits(self.X_in)\n",
        "        self.cost_op = tf.reduce_mean(\n",
        "            tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=self.X_in)\n",
        "        )\n",
        "\n",
        "    def fit(self, X, epochs=1, batch_sz=100, show_fig=False):\n",
        "        N, D = X.shape\n",
        "        n_batches = N//batch_sz\n",
        "\n",
        "        costs = []\n",
        "        print('Training RBM ', self.id)\n",
        "        for i in range(epochs):\n",
        "            print('epoch ', i, end=' ')\n",
        "            for j in range(n_batches):\n",
        "                batch = X[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "                _, c = self.session.run((self.train_op, self.cost_op), feed_dict={self.X_in: batch})\n",
        "                costs.append(c)\n",
        "            print('cost: ', c)\n",
        "\n",
        "        if show_fig:\n",
        "            plt.plot(costs)\n",
        "            plt.show()\n",
        "\n",
        "    def free_energy(self, V):\n",
        "        b = tf.reshape(self.b, (self.D, 1))\n",
        "        term1 = -tf.matmul(V, b)\n",
        "        term1 = tf.reshape(term1, (-1,))\n",
        "\n",
        "        term2 = tf.reduce_sum(\n",
        "            tf.nn.softplus(tf.matmul(V, self.W) + self.c)\n",
        "        )\n",
        "\n",
        "        return term1-term2\n",
        "\n",
        "    def forward_hidden(self, X):\n",
        "        return tf.nn.sigmoid(tf.matmul(X, self.W) + self.c)\n",
        "\n",
        "    def forward_logits(self, X):\n",
        "        Z = self.forward_hidden(X)\n",
        "        return tf.matmul(Z, tf.transpose(self.W)) + self.b\n",
        "\n",
        "    def forward_output(self, X):\n",
        "        return tf.nn.sigmoid(self.forward_logits(X))\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self.session.run(self.p_h_given_v, feed_dict={self.X_in: X})\n",
        "\n",
        "class DNN(object):\n",
        "    def __init__(self, D, hidden_layer_sizes, K):\n",
        "        self.hidden_layers = []\n",
        "        count = 0\n",
        "        current_input = D\n",
        "        for hl_size in hidden_layer_sizes:\n",
        "            self.hidden_layers.append(RBM(current_input, hl_size, count))\n",
        "            count += 1\n",
        "            current_input = hl_size\n",
        "        self.build_final_layer(D, hidden_layer_sizes[-1], K)\n",
        "\n",
        "    def set_session(self, session):\n",
        "        self.session = session\n",
        "\n",
        "        for ae in self.hidden_layers:\n",
        "            ae.set_session(session)\n",
        "\n",
        "    def build_final_layer(self, D, M, K):\n",
        "        self.W = tf.Variable(tf.random_normal(shape=(M, K)))\n",
        "        self.b = tf.Variable(np.zeros(K).astype(np.float32))\n",
        "\n",
        "        self.X = tf.placeholder(tf.float32, shape=(None, D))\n",
        "        self.Y = tf.placeholder(tf.int32, shape=(None,))\n",
        "        logits = self.forward(self.X)\n",
        "\n",
        "        self.cost = tf.reduce_mean(\n",
        "            tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=self.Y)\n",
        "        )\n",
        "        self.train_op = tf.train.AdamOptimizer(1e-2).minimize(self.cost)\n",
        "        self.predict_op = tf.argmax(logits, axis=1)\n",
        "\n",
        "    def fit(self, x_train, y_train, x_test, y_test, epochs=1, batch_sz=100, show_fig=True):\n",
        "        current_input = x_train\n",
        "        for ae in self.hidden_layers:\n",
        "            ae.fit(current_input, epochs=2, show_fig=False)\n",
        "            current_input = ae.transform(current_input)\n",
        "        \n",
        "        N, D = x_train.shape\n",
        "        n_batches = N//batch_sz\n",
        "\n",
        "        costs = []\n",
        "        print('supervised training: ')\n",
        "        for i in range(epochs):\n",
        "            print('epoch ', i+1, end=' ')\n",
        "            x_train, y_train = shuffle(x_train, y_train)\n",
        "            for j in range(n_batches):\n",
        "                x_batch = x_train[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "                y_batch = y_train[j*batch_sz:(j*batch_sz + batch_sz)]\n",
        "                self.session.run(self.train_op, feed_dict={self.X: x_batch, self.Y: y_batch})\n",
        "                c, p = self.session.run((self.cost, self.predict_op), feed_dict={self.X: x_test, self.Y: y_test})\n",
        "                costs.append(c)\n",
        "\n",
        "            print('Cost: ', c, ' Error rate: ', error_rate(p, y_test))\n",
        "\n",
        "        if show_fig:\n",
        "            plt.plot(costs)\n",
        "            plt.show()\n",
        "\n",
        "    def forward(self, X):\n",
        "        current_input = X\n",
        "        for ae in self.hidden_layers:\n",
        "            Z = ae.forward_hidden(current_input)\n",
        "            current_input = Z\n",
        "\n",
        "        return tf.matmul(Z, self.W) + self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RRRnoOewLjQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "7eb6d408-803a-43ab-8570-8401ff6ab947"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test, y_train, y_test = x_train[:4000, :], x_test[:1000, :], y_train[:4000], y_test[:1000]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "D = x_train.shape[1]\n",
        "K = len(set(y_train))\n",
        "dnn = DNN(D, [1000, 750, 500], K)\n",
        "\n",
        "init_op = tf.global_variables_initializer()\n",
        "with tf.Session() as session:\n",
        "    session.run(init_op)\n",
        "    dnn.set_session(session)\n",
        "    dnn.fit(x_train, y_train, x_test, y_test, epochs=20)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training RBM  0\n",
            "epoch  0 cost:  0.3066849\n",
            "epoch  1 cost:  0.24038853\n",
            "Training RBM  1\n",
            "epoch  0 cost:  0.161838\n",
            "epoch  1 cost:  0.13094477\n",
            "Training RBM  2\n",
            "epoch  0 cost:  0.24630822\n",
            "epoch  1 cost:  0.20919073\n",
            "supervised training: \n",
            "epoch  1 Cost:  0.9464794  Error rate:  0.224\n",
            "epoch  2 Cost:  0.7236335  Error rate:  0.18\n",
            "epoch  3 Cost:  0.6194264  Error rate:  0.161\n",
            "epoch  4 Cost:  0.5823334  Error rate:  0.151\n",
            "epoch  5 Cost:  0.5707605  Error rate:  0.144\n",
            "epoch  6 Cost:  0.5519012  Error rate:  0.137\n",
            "epoch  7 Cost:  0.56307477  Error rate:  0.134\n",
            "epoch  8 Cost:  0.5646622  Error rate:  0.131\n",
            "epoch  9 Cost:  0.5656953  Error rate:  0.132\n",
            "epoch  10 Cost:  0.5689893  Error rate:  0.134\n",
            "epoch  11 Cost:  0.57190543  Error rate:  0.134\n",
            "epoch  12 Cost:  0.5733975  Error rate:  0.132\n",
            "epoch  13 Cost:  0.5751075  Error rate:  0.134\n",
            "epoch  14 Cost:  0.5755695  Error rate:  0.135\n",
            "epoch  15 Cost:  0.5766805  Error rate:  0.135\n",
            "epoch  16 Cost:  0.5777141  Error rate:  0.137\n",
            "epoch  17 Cost:  0.5772347  Error rate:  0.137\n",
            "epoch  18 Cost:  0.57742983  Error rate:  0.139\n",
            "epoch  19 Cost:  0.5780324  Error rate:  0.14\n",
            "epoch  20 Cost:  0.5784981  Error rate:  0.14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}