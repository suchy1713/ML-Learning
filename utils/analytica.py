# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kR8LUPxeV4xmGwy0O6Ou_UjgYx6ROdzV
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import missingno as mn
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, MinMaxScaler

sns.set(style="whitegrid")
flatui = ["#9b59b6", "#3498db", "#95a5a6", "#e74c3c", "#34495e", "#2ecc71"]
sns.set_palette(flatui)

def summary(df):
    pd.set_option('display.max_columns', 500)
    try:
        print(df.describe(include=[np.number]), '\n')
    except ValueError:
        print('', end='')
    try:
        print(df.describe(exclude=[np.number]))
    except ValueError:
        print('', end='')
    pd.set_option('display.max_columns', 5)

def head(df, full=True):
    if full:
        pd.set_option('display.max_columns', 500)
        print(df.head())
        pd.set_option('display.max_columns', 5)

    else:
        print(df.head())

def delete_cols(df, indexes):
    return df.drop(indexes, axis=1)

def aggregate(df, column, by):
    if type(by) is not list:
        tmp_df = df[[by, column]]
        pd.set_option('display.max_columns', 500)
        print(tmp_df.groupby([by]).describe())
        pd.set_option('display.max_columns', 5)
    else:
        tmp_df = df[by + [column]]
        pd.set_option('display.max_columns', 500)
        print(tmp_df.groupby(by).describe())
        pd.set_option('display.max_columns', 5)

def scatterplot(df, x, y, hue=None, size=None):
    _, ax = plt.subplots(figsize=(12, 8))
    sns.scatterplot(x, y, hue=hue, size=size, data=df, sizes=(20, 100), ax=ax)

def jointplot(df, x, y):
    sns.jointplot(x, y, kind='reg', data=df, height=8)

def histogram(df, x, bins=None):
    _, ax = plt.subplots(figsize=(12, 8))
    sns.distplot(df[x], ax=ax, bins=bins)

def boxplot(df, x=None, y=None, hue=None):
    _, ax = plt.subplots(figsize=(12, 8))
    if x is None:
        sns.boxplot(data=df, orient="h")
    elif type(x) is list:
        tmp_df = df[x]
        sns.boxplot(data=tmp_df, orient='h')
    else:
        sns.boxplot(x, y, hue=hue, data=df)

def correlation_matrix(df, figsize=(10, 10)):
    fig, ax = plt.subplots(figsize=figsize)
    sns.heatmap(df.corr(), vmax=1.0, center=0, fmt='.2f', square=True, linewidths=.5, annot=True, cbar_kws={"shrink": .70})
    plt.show()

def n():
    print('\n')

def missing_vals(df):
    cols = df.isna().sum()/df.shape[0]
    cols = pd.DataFrame({'Column name': cols.index, 'Missing %': cols.values})
    rows = (df.isna().sum(axis=1)/df.shape[1]).value_counts()
    rows = pd.DataFrame({'Missing %': rows.index, 'Quantity': rows.values})
    print('Columns:')
    print(cols)
    n()
    print('Rows: ')
    print(rows)

def missing_vals_vis(df, figsize=(8, 4)):
    _, ax = plt.subplots(figsize=figsize)
    mn.matrix(df, ax=ax)
    _, ax2 = plt.subplots(figsize=figsize)
    mn.dendrogram(df, ax=ax2)
    _, ax3 = plt.subplots(figsize=figsize)
    mn.bar(df, ax=ax3)

def drop_mostly_missing(df, col_th=0.6, row_th=0.7):
    cols = df.isna().sum()/df.shape[0]
    cols = pd.DataFrame({'name': cols.index, 'missing': cols.values})
    df_tmp = cols.loc[cols['missing'] > col_th]
    df_tmp = df_tmp['name'].values
    ret_df = delete_cols(df, df_tmp)

    rows = ret_df.isna().sum(axis=1)/ret_df.shape[1]
    rows = pd.DataFrame({'index': rows.index, 'missing': rows.values})
    rows_tmp = rows.loc[rows['missing'] > row_th]
    rows_tmp = rows_tmp['index'].values
    ret_df = ret_df.drop(rows_tmp)

    return ret_df

def fill_missing(df, cols='all', strategy='median'):
    if cols == 'all':
        imputer = SimpleImputer(missing_values=np.nan, strategy=strategy)
        imputed_df = pd.DataFrame(imputer.fit_transform(df))
        imputed_df.columns = df.columns
        imputed_df.index = df.index
        return imputed_df
    else:
        imputer = SimpleImputer(missing_values=np.nan, strategy=strategy)
        imputed_df = pd.DataFrame(imputer.fit_transform(df[cols]))
        df[cols] = imputed_df.values
        return df

def normalize(df, scaler, cols='all'):
    if cols == 'all':
        scaled_df = pd.DataFrame(scaler.fit_transform(df))
        scaled_df.columns = df.columns
        scaled_df.index = df.index
        return scaled_df
    elif cols == 'numeric':
        cols = df.select_dtypes([np.number]).columns
        scaled_df = pd.DataFrame(scaler.fit_transform(df[cols]))
        df[cols] = scaled_df.values
        return df
    else:
        scaled_df = pd.DataFrame(scaler.fit_transform(df[cols]))
        df[cols] = scaled_df.values
        return df

def standardize(df, cols='all'):
    return normalize(df, StandardScaler(), cols)

def scale(df, cols='all'):
    return normalize(df, MinMaxScaler(), cols)

def categorical_features(df, cols):
    for c in cols:
        print(c)
        print(df[c].value_counts(), '\n')

def encode_categorical_features(df, cols, drop_first=False):
    return pd.get_dummies(df, columns=cols, drop_first=drop_first)